{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script openai is installed in '/Library/Frameworks/Python.framework/Versions/3.11/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU openai chromadb pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the following line to set the environment variable in the notebook\n",
    "# os.environ[\"OPENAI_API_KEY\"] = 'sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print(\"OPENAI_API_KEY is ready\")\n",
    "\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY environment variable not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>10-20% of people with severe mental disorder r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>25% of patients with melanoma and an objective...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>50% of patients exposed to radiation have acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>8% of burn patients are admitted for hospitali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>A breast cancer patient's capacity to metaboli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              claim\n",
       "0   7  10-20% of people with severe mental disorder r...\n",
       "1   8  25% of patients with melanoma and an objective...\n",
       "2  16  50% of patients exposed to radiation have acti...\n",
       "3  23  8% of burn patients are admitted for hospitali...\n",
       "4  29  A breast cancer patient's capacity to metaboli..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the claim dataset\n",
    "data_path = '/Users/davidkolb/documents/code/kolbeuk-data/vectordb/scifact/data/'\n",
    "\n",
    "claim_df = pd.read_json(f'{data_path}/corpus.jsonl', lines=True)\n",
    "claim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(claim):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"I will ask you to assess a scientific claim. Output only the text 'True' if the claim is true, 'False' if the claim is false, or 'NEE' if there's not enough evidence.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"        \n",
    "Example:\n",
    "\n",
    "Claim:\n",
    "0-dimensional biomaterials show inductive properties.\n",
    "\n",
    "Assessment:\n",
    "False\n",
    "\n",
    "Claim:\n",
    "1/2000 in UK have abnormal PrP positivity.\n",
    "\n",
    "Assessment:\n",
    "True\n",
    "\n",
    "Claim:\n",
    "Aspirin inhibits the production of PGE2.\n",
    "\n",
    "Assessment:\n",
    "False\n",
    "\n",
    "End of examples. Assess the following claim:\n",
    "\n",
    "Claim:\n",
    "{claim}\n",
    "\n",
    "Assessment:\n",
    "\"\"\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "def assess_claims(claims):\n",
    "    responses = []\n",
    "    # Query the OpenAI API\n",
    "    for claim in claims:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=build_prompt(claim),\n",
    "            max_tokens=3,\n",
    "        )\n",
    "        # Strip any punctuation or whitespace from the response\n",
    "        responses.append(response.choices[0].message.content.strip('., '))\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at 100 claims\n",
    "samples = claim_df.sample(50)\n",
    "\n",
    "claims = samples['claim'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groundtruth(evidence):\n",
    "    groundtruth = []\n",
    "    for e in evidence:\n",
    "        # Evidence is empty \n",
    "        if len(e) == 0:\n",
    "            groundtruth.append('NEE')\n",
    "        else:\n",
    "            # In this dataset, all evidence for a given claim is consistent, either SUPPORT or CONTRADICT\n",
    "            if list(e.values())[0][0]['label'] == 'SUPPORT':\n",
    "                groundtruth.append('True')\n",
    "            else:\n",
    "                groundtruth.append('False')\n",
    "    return groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = samples['evidence'].tolist()\n",
    "groundtruth = get_groundtruth(evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(inferred, groundtruth):\n",
    "    assert len(inferred) == len(groundtruth)\n",
    "    confusion = {\n",
    "        'True': {'True': 0, 'False': 0, 'NEE': 0},\n",
    "        'False': {'True': 0, 'False': 0, 'NEE': 0},\n",
    "        'NEE': {'True': 0, 'False': 0, 'NEE': 0},\n",
    "    }\n",
    "    for i, g in zip(inferred, groundtruth):\n",
    "        confusion[i][g] += 1\n",
    "\n",
    "    # Pretty print the confusion matrix\n",
    "    print('\\tGroundtruth')\n",
    "    print('\\tTrue\\tFalse\\tNEE')\n",
    "    for i in confusion:\n",
    "        print(i, end='\\t')\n",
    "        for g in confusion[i]:\n",
    "            print(confusion[i][g], end='\\t')\n",
    "        print()\n",
    "\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_inferred = assess_claims(claims)\n",
    "confusion_matrix(gpt_inferred, groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_inferred = assess_claims(claims)\n",
    "confusion_matrix(gpt_inferred, groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "# We initialize an embedding function, and provide it to the collection.\n",
    "embedding_function = OpenAIEmbeddingFunction(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "chroma_client = chromadb.Client() # Ephemeral by default\n",
    "scifact_corpus_collection = chroma_client.create_collection(name='scifact_corpus', embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "for i in range(0, len(corpus_df), batch_size):\n",
    "    batch_df = corpus_df[i:i+batch_size]\n",
    "    scifact_corpus_collection.add(\n",
    "        ids=batch_df['doc_id'].apply(lambda x: str(x)).tolist(), # Chroma takes string IDs.\n",
    "        documents=(batch_df['title'] + '. ' + batch_df['abstract'].apply(lambda x: ' '.join(x))).to_list(), # We concatenate the title and abstract.\n",
    "        metadatas=[{\"structured\": structured} for structured in batch_df['structured'].to_list()] # We also store the m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_query_result = scifact_corpus_collection.query(query_texts=claims, include=['documents', 'distances'], n_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_with_context(claim, context):\n",
    "    return [{'role': 'system', 'content': \"I will ask you to assess whether a particular scientific claim, based on evidence provided. Output only the text 'True' if the claim is true, 'False' if the claim is false, or 'NEE' if there's not enough evidence.\"}, \n",
    "            {'role': 'user', 'content': f\"\"\"\"\n",
    "The evidence is the following:\n",
    "\n",
    "{' '.join(context)}\n",
    "\n",
    "Assess the following claim on the basis of the evidence. Output only the text 'True' if the claim is true, 'False' if the claim is false, or 'NEE' if there's not enough evidence. Do not output any other text. \n",
    "\n",
    "Claim:\n",
    "{claim}\n",
    "\n",
    "Assessment:\n",
    "\"\"\"}]\n",
    "\n",
    "\n",
    "def assess_claims_with_context(claims, contexts):\n",
    "    responses = []\n",
    "    # Query the OpenAI API\n",
    "    for claim, context in zip(claims, contexts):\n",
    "        # If no evidence is provided, return NEE\n",
    "        if len(context) == 0:\n",
    "            responses.append('NEE')\n",
    "            continue\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=build_prompt_with_context(claim=claim, context=context),\n",
    "            max_tokens=3,\n",
    "        )\n",
    "        # Strip any punctuation or whitespace from the response\n",
    "        responses.append(response.choices[0].message.content.strip('., '))\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_with_context_evaluation = assess_claims_with_context(claims, claim_query_result['documents'])\n",
    "confusion_matrix(gpt_with_context_evaluation, groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_query_result(query_result, distance_threshold=0.25):\n",
    "# For each query result, retain only the documents whose distance is below the threshold\n",
    "    for ids, docs, distances in zip(query_result['ids'], query_result['documents'], query_result['distances']):\n",
    "        for i in range(len(ids)-1, -1, -1):\n",
    "            if distances[i] > distance_threshold:\n",
    "                ids.pop(i)\n",
    "                docs.pop(i)\n",
    "                distances.pop(i)\n",
    "    return query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_claim_query_result = filter_query_result(claim_query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_with_filtered_context_evaluation = assess_claims_with_context(claims, filtered_claim_query_result['documents'])\n",
    "confusion_matrix(gpt_with_filtered_context_evaluation, groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hallucination_prompt(claim):\n",
    "    return [{'role': 'system', 'content': \"\"\"I will ask you to write an abstract for a scientific paper which supports or refutes a given claim. It should be written in scientific language, include a title. Output only one abstract, then stop.\n",
    "    \n",
    "    An Example:\n",
    "\n",
    "    Claim:\n",
    "    A high microerythrocyte count raises vulnerability to severe anemia in homozygous alpha (+)- thalassemia trait subjects.\n",
    "\n",
    "    Abstract:\n",
    "    BACKGROUND The heritable haemoglobinopathy alpha(+)-thalassaemia is caused by the reduced synthesis of alpha-globin chains that form part of normal adult haemoglobin (Hb). Individuals homozygous for alpha(+)-thalassaemia have microcytosis and an increased erythrocyte count. Alpha(+)-thalassaemia homozygosity confers considerable protection against severe malaria, including severe malarial anaemia (SMA) (Hb concentration < 50 g/l), but does not influence parasite count. We tested the hypothesis that the erythrocyte indices associated with alpha(+)-thalassaemia homozygosity provide a haematological benefit during acute malaria.   \n",
    "    METHODS AND FINDINGS Data from children living on the north coast of Papua New Guinea who had participated in a case-control study of the protection afforded by alpha(+)-thalassaemia against severe malaria were reanalysed to assess the genotype-specific reduction in erythrocyte count and Hb levels associated with acute malarial disease. We observed a reduction in median erythrocyte count of approximately 1.5 x 10(12)/l in all children with acute falciparum malaria relative to values in community children (p < 0.001). We developed a simple mathematical model of the linear relationship between Hb concentration and erythrocyte count. This model predicted that children homozygous for alpha(+)-thalassaemia lose less Hb than children of normal genotype for a reduction in erythrocyte count of >1.1 x 10(12)/l as a result of the reduced mean cell Hb in homozygous alpha(+)-thalassaemia. In addition, children homozygous for alpha(+)-thalassaemia require a 10% greater reduction in erythrocyte count than children of normal genotype (p = 0.02) for Hb concentration to fall to 50 g/l, the cutoff for SMA. We estimated that the haematological profile in children homozygous for alpha(+)-thalassaemia reduces the risk of SMA during acute malaria compared to children of normal genotype (relative risk 0.52; 95% confidence interval [CI] 0.24-1.12, p = 0.09).   \n",
    "    CONCLUSIONS The increased erythrocyte count and microcytosis in children homozygous for alpha(+)-thalassaemia may contribute substantially to their protection against SMA. A lower concentration of Hb per erythrocyte and a larger population of erythrocytes may be a biologically advantageous strategy against the significant reduction in erythrocyte count that occurs during acute infection with the malaria parasite Plasmodium falciparum. This haematological profile may reduce the risk of anaemia by other Plasmodium species, as well as other causes of anaemia. Other host polymorphisms that induce an increased erythrocyte count and microcytosis may confer a similar advantage.\n",
    "\n",
    "    End of example. \n",
    "    \n",
    "    \"\"\"}, {'role': 'user', 'content': f\"\"\"\"\n",
    "    Perform the task for the following claim.\n",
    "\n",
    "    Claim:\n",
    "    {claim}\n",
    "\n",
    "    Abstract:\n",
    "    \"\"\"}]\n",
    "\n",
    "\n",
    "def hallucinate_evidence(claims):\n",
    "    # Query the OpenAI API\n",
    "    responses = []\n",
    "    # Query the OpenAI API\n",
    "    for claim in claims:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=build_hallucination_prompt(claim),\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucinated_evidence = hallucinate_evidence(claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucinated_query_result = scifact_corpus_collection.query(query_texts=hallucinated_evidence, include=['documents', 'distances'], n_results=3)\n",
    "filtered_hallucinated_query_result = filter_query_result(hallucinated_query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_with_hallucinated_context_evaluation = assess_claims_with_context(claims, filtered_hallucinated_query_result['documents'])\n",
    "confusion_matrix(gpt_with_hallucinated_context_evaluation, groundtruth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
