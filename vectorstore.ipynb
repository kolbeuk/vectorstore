{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5921de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain import hub\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ca72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67e90410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have three documents in a directory 'docs' with different formats\n",
    "document_paths = [\n",
    "    'musk.txt',   # Replace with the actual path to your first document\n",
    "    'bezos.txt'   # Replace with the actual path to your second document\n",
    "]\n",
    "# Initialize an empty list to store all loaded documents\n",
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "907f31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in document_paths:\n",
    "    loader = TextLoader(path)\n",
    "    # Load the document and add it to the list\n",
    "    documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ddbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67e69f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e6b0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a human being and the leader? Well, I don't really know Elon very well. You know, I know his public persona, but I also know you can't know anyone by their public persona. It's impossible. I mean, you may think you do, but I guarantee you don't. So I don't really know you know Elon way better than I do, Lex. But in terms of his judging by the results, he must be a very capable leader. There's no way you could have, you know, Tesla and SpaceX without being a capable leader. It's impossible. Hey, I just, I hope you guys hang out sometimes. Shake hands and sort of have a kind of friendship that would inspire just the entirety of humanity. Because what you're doing is like one of the big grand challenges ahead of humanity. Well, I agree with you. And I think in a lot of these endeavors, we're very like-minded. Yeah. So I think, you know, I'm not saying we're identical, but I think we're very like-minded. And so, I, you know, I love that idea. I go back to sexy pictures on your Instagram.\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(\n",
    "    \"What is elon like as a leader\"\n",
    ")\n",
    "len(retrieved_docs)\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b13934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: filler question \n",
      "Context: filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(\n",
    "    prompt.invoke(\n",
    "        {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    "    ).to_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb0f0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1be663a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know Elon Musk personally, but based on the context, it seems that he is seen as a capable leader due to the success of Tesla and SpaceX. However, I cannot provide a detailed assessment of his leadership style or qualities."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"What is elon like as a leader?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
